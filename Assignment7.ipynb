{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1027, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = './horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=False, num_workers=1) \n",
    "\n",
    "for i, data in enumerate(trainloader):\n",
    "    \n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    trnInputs, trnLabels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    \n",
    "    #make inputs [1027, 1, 100, 100] to [10000,1027]\n",
    "    trnInputs = trnInputs.view(1027, 10000)\n",
    "    trnInputs = trnInputs.T\n",
    "    trnInputs = trnInputs.double()\n",
    "    trnLabels = trnLabels.double()\n",
    "\n",
    "\n",
    "# load validation images of the batch size for every iteration\n",
    "for i, data in enumerate(valloader):\n",
    "\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    valInputs, valLabels = data\n",
    "\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    #make [256, 1, 100, 100] to [10000,256]\n",
    "    valInputs = valInputs.view(256, 10000)\n",
    "    valInputs = valInputs.T\n",
    "    valInputs = valInputs.double()\n",
    "    valLabels = valLabels.double()\n",
    "\n",
    "\n",
    "totalTrnNum = trnLabels.shape[0]\n",
    "totalValNum = valLabels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class Linear(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        self.number_class   = num_classes\n",
    "\n",
    "        _size_image     = 100* 100\n",
    "        _num1           = 50\n",
    "        _num2           = 50\n",
    "        \n",
    "        self.fc1        = nn.Linear(_size_image, _num1, bias=True)\n",
    "        self.fc2        = nn.Linear(_num1, _num2, bias=True)\n",
    "        self.fc3        = nn.Linear(_num2, num_classes, bias=True)\n",
    "\n",
    "        self.fc_layer1  = nn.Sequential(self.fc1, nn.ReLU(True))\n",
    "        self.fc_layer2  = nn.Sequential(self.fc2, nn.ReLU(True))\n",
    "        self.fc_layer3  = nn.Sequential(self.fc3, nn.ReLU(True))\n",
    "        \n",
    "        self.classifier = nn.Sequential(self.fc_layer1, self.fc_layer2, self.fc_layer3)\n",
    "        \n",
    "        self._initialize_weight()        \n",
    "        \n",
    "    def _initialize_weight(self):\n",
    "\n",
    "        for m in self.modules():\n",
    "            \n",
    "\n",
    "            if type(m) == nn.Linear:\n",
    "            \n",
    "                n = m.in_features\n",
    "                m.weight.data.uniform_(- 1.0 / math.sqrt(n), 1.0 / math.sqrt(n))\n",
    "                print(m.weight)\n",
    "                print(m.weight.shape)\n",
    "                if m.bias is not None:\n",
    "\n",
    "                    m.bias.data.zero_()\n",
    "                    \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0098, -0.0080, -0.0012,  ..., -0.0022, -0.0037,  0.0083],\n",
      "        [ 0.0060, -0.0034,  0.0095,  ..., -0.0081, -0.0046, -0.0027],\n",
      "        [-0.0065,  0.0070,  0.0063,  ...,  0.0094, -0.0073, -0.0077],\n",
      "        ...,\n",
      "        [-0.0060, -0.0041, -0.0009,  ...,  0.0041, -0.0086,  0.0092],\n",
      "        [-0.0028,  0.0008,  0.0065,  ...,  0.0097, -0.0061, -0.0090],\n",
      "        [-0.0010, -0.0029, -0.0012,  ..., -0.0031, -0.0082,  0.0080]],\n",
      "       requires_grad=True)\n",
      "torch.Size([50, 10000])\n",
      "Parameter containing:\n",
      "tensor([[ 0.1015, -0.0426, -0.0630,  ...,  0.0982,  0.0201, -0.0530],\n",
      "        [-0.0824,  0.0916,  0.0961,  ..., -0.0355,  0.0422,  0.1190],\n",
      "        [ 0.1024, -0.1331,  0.0658,  ...,  0.0187,  0.0220, -0.0627],\n",
      "        ...,\n",
      "        [-0.1110, -0.1352,  0.0711,  ..., -0.0149,  0.0544, -0.0500],\n",
      "        [-0.0168, -0.0974, -0.0347,  ...,  0.1009, -0.1349,  0.0268],\n",
      "        [-0.0027, -0.0967, -0.1262,  ...,  0.0390, -0.0528,  0.0289]],\n",
      "       requires_grad=True)\n",
      "torch.Size([50, 50])\n",
      "Parameter containing:\n",
      "tensor([[-0.1250, -0.1281,  0.0441,  0.0968,  0.1214,  0.0273,  0.0592,  0.0644,\n",
      "          0.0521,  0.0434,  0.0489,  0.0204, -0.0653,  0.1300,  0.0853, -0.0385,\n",
      "         -0.1112, -0.0686,  0.1175, -0.1328, -0.0957,  0.0727, -0.0249, -0.1206,\n",
      "         -0.0499, -0.0379, -0.0285, -0.0460,  0.0669, -0.0966,  0.0580, -0.0478,\n",
      "         -0.0063, -0.1042,  0.0081, -0.0593, -0.0218, -0.0213, -0.1040,  0.0848,\n",
      "         -0.0003, -0.0189, -0.0277, -0.0196, -0.0879, -0.1291,  0.0520, -0.0783,\n",
      "          0.0271, -0.0790],\n",
      "        [ 0.1107,  0.0454, -0.1035,  0.0549, -0.0346,  0.1214,  0.1201,  0.0894,\n",
      "          0.0763,  0.0163,  0.1160,  0.0710, -0.0461, -0.1194, -0.0476, -0.0702,\n",
      "          0.0134,  0.0986,  0.0695,  0.0347, -0.1157,  0.0144,  0.0685, -0.0961,\n",
      "         -0.1275, -0.0161, -0.0742,  0.1185,  0.0283, -0.0054, -0.0019,  0.0063,\n",
      "          0.1084,  0.0023, -0.1328,  0.0395, -0.1262, -0.1378,  0.1189,  0.0873,\n",
      "         -0.0680, -0.0904, -0.1314,  0.0878,  0.1224, -0.0239,  0.1412,  0.0565,\n",
      "         -0.1172, -0.0691]], requires_grad=True)\n",
      "torch.Size([2, 50])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "parameter group didn't specify a value of required optimization parameter lr",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-904921675770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0moptimizer\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mobjective\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrequired\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 raise ValueError(\"parameter group didn't specify a value of required optimization parameter \" +\n\u001b[0;32m--> 207\u001b[0;31m                                  name)\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mparam_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: parameter group didn't specify a value of required optimization parameter lr"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# import packages\n",
    "# -----------------------------------------------------------------------------\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime \n",
    "import csv\n",
    "import configparser\n",
    "import argparse\n",
    "import platform\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from random import shuffle\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load dataset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "#set_train   = \n",
    "#set_test    = \n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load neural network model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "model = Linear(num_classes=num_classes)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Set the flag for using cuda\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "bCuda = 0\n",
    "\n",
    "if bCuda:\n",
    " \n",
    "    model.cuda()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# optimization algorithm\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "optimizer   = optim.SGD(model.parameters())\n",
    "objective   = nn.CrossEntropyLoss()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for training the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def train():\n",
    "\n",
    "    # print('train the model at given epoch')\n",
    "\n",
    "    loss_train          = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for idx_batch, (data, target) in enumerate(loader_train):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train_batch    = loss.item() / len(data)\n",
    "        loss_train.append(loss_train_batch)\n",
    "        \n",
    "    loss_train_mean     = np.mean(loss_train)\n",
    "    loss_train_std      = np.std(loss_train)\n",
    "\n",
    "    return {'loss_train_mean': loss_train_mean, 'loss_train_std': loss_train_std}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for testing the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test():\n",
    "\n",
    "    # print('test the model at given epoch')\n",
    "\n",
    "    accuracy_test   = []\n",
    "    loss_test       = 0\n",
    "    correct         = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for idx_batch, (data, target) in enumerate(loader_test):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        loss_test   += loss.item()\n",
    "        pred        = output.data.max(1)[1]\n",
    "        correct     += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    loss_test       = loss_test / len(loader_test.dataset)\n",
    "    accuracy_test   = 100. * float(correct) / len(loader_test.dataset)\n",
    "\n",
    "    return {'loss_test': loss_test, 'accuracy_test': accuracy_test}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# iteration for the epoch\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "for e in range(epoch):\n",
    "        \n",
    "    result_train    = train()\n",
    "    result_test     = test()\n",
    "\n",
    "    loss_train_mean[e]  = result_train['loss_train_mean']\n",
    "    loss_train_std[e]   = result_train['loss_train_std']\n",
    "    loss_test[e]        = result_test['loss_test']\n",
    "    accuracy_test[e]    = result_test['accuracy_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
